#' Substructure recommendation for a "library" of unknown compounds
#'
#' The function recommends substructures for unknown spectra stored in a mgf file.
#'
#' @param library A list generated by the function library_generator() or the name of mgf spectral library file
#' @param type Character. Two algorithms focused either on "drug" or "metabolite"
#' @param tops Integer. Top recommended substructures in the output mgf file
#' @param max_peaks Integer. Top most intense peaks kept in the spectra
#' @param min_relative Numeric between 0.1 and 1. Minimum relative intensity of peaks to not be considered as noise.
#' @param output String. File name of output library.
#'
#' @return
#' \itemize{
#'    \item{library_annotated:}{ Library annotated}
#'    \item{sub_extracted:}{ Library object that contain found scans.}
#'    \item{MGF FILE:}{ A MGF file with annotated substructures will be written in user's folder.}
#' }
#'
#' @author Youzhong Liu, \email{Youzhong.Liu@uantwerpen.be}
#'
#' @examples
#'
#' data(DRUG_THERMO_LIBRARY)
#' results = library_messar(library2, type = "drug", tops = 5, output = "thermo_substructure.mgf")
#'
#' @importFrom MSnbase fData readMgfData
#' @importFrom tools file_ext
#' @importFrom stringr str_replace_all fixed
#'
#' @export

library_messar<-function(library, type = c("drug", "metabolite"), tops = 5, max_peaks = 200, min_relative = 0.1, output="library_messar_drug.mgf"){
  
  options(stringsAsFactors = FALSE)
  options(warn=-1)
  
  if (type=="drug"){
    data(DRUG_RULE_DB)
    rules0 = drug_rules0
    rules_id_list = drug_rules_id_list
    rule_fragments = drug_rule_fragments
    rule_nloss = drug_rule_nloss
    rules_training = drug_rules_training
  } else {data(METABOLITE_RULE_DB)}
  
  #################
  ### Check inputs:
  #################
  
  if (missing(library)){
    stop("Please provide the output of library_generator() or a .mgf file as input library!")}
  
  if (is.character(library)){
    if (file_ext(library)!="mgf"){
      stop("The file extension of your input library must be mgf!")
    }}
  
  if (is.list(library)){
    if (length(library)==2 & "complete" %in% names(library)){
      library = library$complete
    }
    if (length(library)!=2 || (!is.list(library$sp)) || !is.data.frame(library$metadata)){
      stop("Please make sure your input library is a valid output of library_generator()!")
    }}
  
  library = library_manager(library, query = "MSLEVEL = 1")
  
  if (nrow(library$LEFT$metadata)==0){stop("No MS/MS records!")}
  
  ###########################
  ##### MESSAR parameters####
  ###########################
  
  test_data = library$LEFT
  
  lib_metadata = test_data$metadata
  lib_sp = test_data$sp
  
  NT = nrow(lib_metadata)
  
  lib_sp = lapply(lib_sp, function(x) x[order(x[,2], decreasing = T),]) # Filter>0.1
  lib_sp = lapply(lib_sp, function(x) x[1:min(max_peaks, nrow(x)),]) # Filter>0.1
  lib_sp = lapply(lib_sp, function(x) x[order(x[,1]),]) # Filter>0.1
  
  lib_sp = lapply(lib_sp, function(x) cbind(x[,1], x[,2]/max(x[,2])*100))
  lib_sp = lapply(lib_sp, function(x) x[x[,2]>min_relative,]) # Filter>0.1

  lib_mz = as.numeric(lib_metadata$PEPMASS)
  
  ################
  ##### MESSAR####
  ################
  
  sub_extracted_list =  list()
  estimation_list = rep("0", NT)

  for (i in 1:NT){
    
    print(i)
    
    sp = lib_sp[[i]]
    
    sub_extracted_list[[i]] = NULL
  
    if (nrow(sp)>=3){
    
      id_matched = c() # ID matched to the aligned features
    
      # Search fragments:
    
      frags = sp[,1]
      frags = frags[frags <= lib_mz[i]-0.5]
      for (frag in frags){
        error = abs(rule_fragments$Mass-frag)
        valid = which.min(error)
        if (error[valid]<0.003){
          id_matched = c(id_matched, rule_fragments$ID[valid])
        }
      }
    
      # Search NLoss:
    
      nloss = lib_mz[i] - sp[,1]
      nloss = nloss[nloss>0.5] # Must higher than 0.5
      for (nl in nloss){
        error = abs(rule_nloss$Mass - nl)
        valid = which.min(error)
        if (error[valid]<0.003){
          id_matched = c(id_matched, rule_nloss$ID[valid])
        }
     }
    
     # Match to rules and scoring:
    
      matched_rule_score = lapply(rules_id_list, function(x) intersect(as.character(id_matched), x))
      matched_rule_score = sapply(matched_rule_score,length)/log2(rules0$SIZE)

     # Scoring substructures:
    
      substructure_estimated = cbind.data.frame(SUBSTRUCTURE = rules0$SUBSTRUCTURE, SCORE = matched_rule_score)
      substructure_estimated = substructure_estimated[substructure_estimated[,2]>0,,drop=FALSE]
      substructure_estimated = substructure_estimated[order(substructure_estimated[,2], decreasing=T),]

      if (nrow(substructure_estimated)>0){
        sub_extracted_list[[i]] = substructure_estimated
        tops1 = min(nrow(substructure_estimated), tops)
        substructures = substructure_estimated[1:tops1,1]
        substructures = paste0(substructures, collapse = ":")
        estimation_list[i] = substructures
      }
    }
  }
  
  ##############
  #####Output###
  ##############
  
  lib_metadata = cbind.data.frame(lib_metadata, OUTPUT_SUBSTRUCTURE = estimation_list)
  test_data$metadata = lib_metadata
  
  writeMGF2(test_data, con = output)
  return(list(library_annotated = test_data, sub_extracted = sub_extracted_list))
}

###########################
### Internal functions:####
###########################

ppm_distance<-function(x,y){
  return(abs((x-y)/y*1000000))
}

